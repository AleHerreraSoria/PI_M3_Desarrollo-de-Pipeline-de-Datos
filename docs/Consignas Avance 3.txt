Luego de asegurar la correcta recolección de datos, la empresa necesita transformar esa información 
en conocimiento accionable. Tu responsabilidad como Ingeniero de Datos se enfoca ahora en construir
 los procesos que convertirán los datos crudos en activos útiles para el análisis.
Implementarás transformaciones complejas mediante scripts en SQL o PySpark, integrando datos estructurados
 y no estructurados. Estas transformaciones estarán guiadas por las preguntas de negocio definidas
  en la etapa de diseño, y su objetivo será estructurar los datos para alimentar las capas analítica 
  y de consumo del Data Warehouse.
Esta fase es crítica: el valor de los datos se revela aquí, cuando se convierten en respuestas a preguntas
 estratégicas. Serás quien valide que cada capa del Data Warehouse almacene datos limpios, consistentes 
 y correctamente transformados para su análisis posterior.

Situación
Tu rol como Ingeniero de Datos se centra en transformarlos en información útil para el negocio.
→ Implementarás procesos con SQL o PySpark que integran y estructuran datos, guiados por preguntas estratégicas.
→ Tu objetivo es asegurar que el Data Warehouse contenga datos limpios, consistentes y listos para el análisis.

Conozcamos la consigna del 3er.Avance.
1. Scripts en SQL/Pyspark que realicen las transformaciones necesarias según las preguntas de negocio planteadas.
2. Transformaciones que permitan integrar datos no estructurados con los datos estructurados existentes.
3. Validación de que las transformaciones se ejecutan correctamente y los datos se almacenan en las capas
 correspondientes del Data Warehouse.

 Para ello,deberemos estar segusros de tener los conocimientos necesarios:
- Fundamentos de arquitectura de datos 
- Data Warehousing
- Procesos de ETL, ELT, ETLT de datos: extract, transform and load 
- Optimización de flujos ETL/ELT, ETL

y contar con el Tech Stack necesario
- Snowflake
- Python
- SQL
- Docker

